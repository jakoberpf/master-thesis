\chapter{Analysis of processing results}
\label{analysis_processing}
In this chapter the result of the data processing will be evaluated. Starting with the evaluation processing, which clusters the FCD, forms congestion events, finds adjacent incident and exports a list of congestion-incident matched. The second section will elaborate on the results of the correlation processing and use the results for a further analysis of relations.

\section{Evaluation Processing}
\label{analysis_processing_evaluation}
The results of the clustering and matching algorithm where visually reviewed to verify the performance. Thought iterative adjustments of the input parameters the clustering and matching algorithm where calibrated to a sufficient representation level (see final input parameters in \cref{methodology_detection} and \cref{methodology_matching}).

\todo{Add Figures of clustering as proof} 

\section{Correlation Processing}
\label{analysis_processing_correlation}
The resulting datasets created by the evaluation tool (see section \cref{methodology_detection} \cref{methodology_matching} and \cref{methodology_data_processing}) which is tasked with the detection and clustering of jams and search for adjacent incidents, are then processed by the correlation tool (\cref{methodology_correlation_processing}). The correlation tool calculates multiple matrix tables with the correlation effect size, correlation significance and used correction coefficient for all variable combinations. From these tables and interpretation guidelines defined in \cref{correlation_coefficient_types} for each coefficient type, we can deviated the strength of correlation and significance (see \cref{correlation_significance}) for each variable combination. To recap \cref{correlation_coefficient_types}, \cref{tbl:correlation_interpretation_guidelines} shows the guidelines for a weak, moderate and strong correlation effect size of the coefficients $r$,$\eta$,$r_{pq}$,$\tau$ and $V$. The significance is evaluated by an $\alpha$-level of .05.
\begin{table}[ht!]
	\centering
	\begin{tabular}{r|c|c|c}  
		\toprule
		Coefficient & Weak 	& Moderate 	& Strong \\
		\midrule
		$r$ 		& .30	& .50		& .80 \\
		$\eta$ 		& < .06 & .06		& .14 \\
		$r_{pq}$	& < .30	& .30		& .50 \\
		$\tau$ 		& < .30	& .30		& .50 \\
		$V$ 		& < .30	& .30		& .40 \\
		\bottomrule
	\end{tabular}
	\caption{Correlation effect size interpretation for coefficient $r$,$\eta$,$r_{pq}$,$\tau$ and $V$}
	\label{tbl:correlation_interpretation_guidelines}
\end{table}
In the case of correlated and significant variables, it still needs to be determined what the found correlation predicates. This is done via the Post Hoc test, defined in \cref{correlation_posthoc}, which tests for for significance differences between the groups via the pairwise Wilcoxon $T$-test. The rest of this chapter is dedicated to elaborate on this tedious process of testing all groups for significance differences. This involves a enormous number of tables which need to be evaluated and involves repetitions, but is necessary to cover all assumptions and interpretations, referenced later on. For a summary of the significant differences and their interpretations, please forward to \cref{analysis_summary}.

% -------------------------
% -------- BAYSIS ---------
% -------------------------
% Global
\input{chapters/chapter6_1.tex}
\clearpage
% Initiator
\input{chapters/chapter6_2.tex}
\clearpage
% % Effector
\input{chapters/chapter6_3.tex}
\clearpage
% % Follower
\input{chapters/chapter6_4.tex}
\clearpage

% ------------------------
% -------- ArbIS ---------
% ------------------------
% Global
\input{chapters/chapter6_5.tex}
\clearpage
% Initiator





